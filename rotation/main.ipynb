{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "device_in_use = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device_in_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ../mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../mnist_data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to convert the data to a PyTorch Tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Download the training data\n",
    "train_dataset = MNIST(root='../mnist_data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='../mnist_data', train=False, download=True, transform=transform)\n",
    "\n",
    "rotated_mnist_trainset = RotatedMNISTDataset(train_dataset)\n",
    "rotated_mnist_testset = RotatedMNISTDataset(test_dataset)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(rotated_mnist_trainset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(rotated_mnist_testset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_18 = models.resnet18()\n",
    "\n",
    "# Change the first convolutional layer to accept 1-channel input\n",
    "resnet_18.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "#get rid of maxpooling\n",
    "resnet_18.maxpool = nn.Identity()\n",
    "#translational invariance\n",
    "\n",
    "# Modify the final layer to output a single value (the predicted rotation angle)\n",
    "num_features = resnet_18.fc.in_features\n",
    "resnet_18.fc = nn.Linear(num_features, 3)\n",
    "\n",
    "# Now move the modified model to the GPU\n",
    "resnet_18 = resnet_18.to(device_in_use)\n",
    "\n",
    "optimizer = torch.optim.Adam(resnet_18.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m custom_loss(outputs, ground_truth, (\u001b[38;5;241m.15\u001b[39m,\u001b[38;5;241m.85\u001b[39m))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     28\u001b[0m total_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Accumulate the training loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\smbm2\\AppData\\Local\\miniconda3\\envs\\digit-restoration-env\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\smbm2\\AppData\\Local\\miniconda3\\envs\\digit-restoration-env\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\smbm2\\AppData\\Local\\miniconda3\\envs\\digit-restoration-env\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "epochs=500\n",
    "early_stopping=EarlyStopping(patience=7, verbose=True, mode='min')\n",
    "for epoch in range(epochs):\n",
    "    resnet_18.train()\n",
    "    total_loss_train = 0  # Initialize total training loss\n",
    "    for original_image, rotated_image, rotation_center, rotation_angle in trainloader:\n",
    "        # Move inputs to the device\n",
    "        rotated_image = rotated_image.to(device_in_use)\n",
    "\n",
    "        ground_truth = torch.cat((rotation_center, rotation_angle), dim=1).to(device_in_use)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = resnet_18(rotated_image).squeeze()\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = custom_loss(outputs, ground_truth, (.15,.85))\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss_train += loss.item()  # Accumulate the training loss\n",
    "\n",
    "    avg_loss_train = total_loss_train / len(trainloader)  # Compute the average training loss\n",
    "\n",
    "    train_loss.append(avg_loss_train)\n",
    "\n",
    "    resnet_18.eval()\n",
    "    total_loss_test = 0  # Initialize total test loss\n",
    "    with torch.no_grad():\n",
    "        for original_image, rotated_image, rotation_center, rotation_angle in testloader:\n",
    "            # Move inputs to the device\n",
    "            rotated_image = rotated_image.to(device_in_use)\n",
    "\n",
    "            ground_truth = torch.cat((rotation_center, rotation_angle), dim=1).to(device_in_use)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = resnet_18(rotated_image).squeeze()\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss_test = custom_loss(outputs, ground_truth, (.15,.85))\n",
    "\n",
    "            total_loss_test += loss_test.item()  # Accumulate the test loss\n",
    "\n",
    "    avg_loss_test = total_loss_test / len(testloader) \n",
    "\n",
    "    test_loss.append(avg_loss_test)\n",
    "\n",
    "    early_stopping(avg_loss_test)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    # Print loss information\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], TRAIN | Loss: {avg_loss_train}, TEST | Loss: {avg_loss_test}')\n",
    "\n",
    "torch.save(resnet_18, 'resnet_18_lr_0.0001_custom.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "resnet_18.eval()\n",
    "\n",
    "# Initialize an empty list to store data\n",
    "data = []\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    for original_image, rotated_image, rotation_center, rotation_angle in testloader:\n",
    "        # Move inputs to the device\n",
    "        rotated_image = rotated_image.to(device_in_use)\n",
    "        \n",
    "        # Forward pass to get the output from the model\n",
    "        outputs = resnet_18(rotated_image).cpu()\n",
    "        \n",
    "        # Extract the predicted rotation centers and angles from the outputs\n",
    "        predicted_rotation_center = outputs[:, :2]  # Assuming the first two values are the center\n",
    "        predicted_rotation_angle = outputs[:, 2]   # Assuming the third value is the angle\n",
    "        \n",
    "        # Convert to numpy arrays for easier handling\n",
    "        rotation_center_np = rotation_center.numpy()\n",
    "        rotation_angle_np = rotation_angle.numpy().reshape(-1, 1)  # Reshape for concatenation\n",
    "        predicted_rotation_center_np = predicted_rotation_center.numpy()\n",
    "        predicted_rotation_angle_np = predicted_rotation_angle.numpy().reshape(-1, 1)\n",
    "        \n",
    "        # Iterate over the batch and append each item to the data list\n",
    "        for i in range(len(rotated_image)):\n",
    "            data.append([\n",
    "                rotation_center_np[i][0], rotation_center_np[i][1],  # Ground truth center x, y\n",
    "                rotation_angle_np[i][0],                            # Ground truth angle\n",
    "                predicted_rotation_center_np[i][0], predicted_rotation_center_np[i][1],  # Predicted center x, y\n",
    "                predicted_rotation_angle_np[i][0]                   # Predicted angle\n",
    "            ])\n",
    "\n",
    "# Create a DataFrame from the accumulated data\n",
    "columns = ['Center_X_True', 'Center_Y_True', 'Angle_True', 'Center_X_Pred', 'Center_Y_Pred', 'Angle_Pred']\n",
    "df_1 = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_error(row):\n",
    "    if row['Angle_True']*row['Angle_Pred'] > 0:\n",
    "        return np.abs(row['Angle_True'] - row['Angle_Pred']) % 360\n",
    "    else:\n",
    "        temp = np.abs(row['Angle_True']) + np.abs(row['Angle_Pred'])\n",
    "        return min(temp, 360-temp)\n",
    "    \n",
    "\n",
    "for i in [df_1]:\n",
    "    i['Error_Angle'] = i.apply(angle_error, axis=1)\n",
    "    i['Error_Center_Distance'] = np.sqrt((i['Center_X_True'] - i['Center_X_Pred'])**2 + (i['Center_Y_True'] - i['Center_Y_Pred'])**2)\n",
    "    print(f\"Average Angle Error: {np.mean(i['Error_Angle'])}\")\n",
    "    print(f\"Average Center Error: {np.mean(i['Error_Center_Distance'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single batch of data\n",
    "dataiter = iter(testloader)\n",
    "\n",
    "# Move the model to evaluation mode\n",
    "resnet_18.eval()\n",
    "\n",
    "# Get a single batch of data\n",
    "original_image, rotated_image, rotation_center, rotation_angle = next(dataiter)\n",
    "\n",
    "# Select the first image in the batch\n",
    "original_image = original_image[0]  \n",
    "rotated_image = rotated_image[0]  # Add batch dimension\n",
    "actual_angle = rotation_angle[0]\n",
    "actual_center = rotation_center[0]\n",
    "\n",
    "rotated_image_batched = rotated_image.unsqueeze(0)\n",
    "rotated_image_batched = rotated_image_batched.to(device_in_use)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = resnet_18(rotated_image_batched).cpu()  \n",
    "        \n",
    "    # Extract the predicted rotation centers and angles from the outputs\n",
    "    predicted_rotation_center = outputs[:, :2]  # Assuming the first two values are the center\n",
    "    predicted_rotation_angle = outputs[:, 2]   # Assuming the third value is the angle\n",
    "\n",
    "print(predicted_rotation_angle)\n",
    "print(predicted_rotation_center)\n",
    "\n",
    "# Ensure predicted_rotation_center and predicted_rotation_angle are on the CPU\n",
    "predicted_rotation_center_cpu = predicted_rotation_center.cpu()\n",
    "predicted_rotation_angle_cpu = predicted_rotation_angle.item()  # .item() already ensures it's a CPU scalar\n",
    "\n",
    "original_image_cv = tensor_to_cv(original_image)\n",
    "cv_image = tensor_to_cv(rotated_image)\n",
    "\n",
    "center = tuple(predicted_rotation_center.flatten().tolist())\n",
    "# Format each element in the tuple to two decimal places\n",
    "formatted_tuple = tuple(f\"{value:.2f}\" for value in center)\n",
    "\n",
    "# Convert the tuple of strings to a single string representation\n",
    "formatted_string = ', '.join(formatted_tuple)\n",
    "\n",
    "# Use the CPU versions of center and angle\n",
    "registered = rotate_image(cv_image, center, -predicted_rotation_angle_cpu)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_image_cv, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cv_image, cmap='gray')\n",
    "plt.title('Transformed Digit')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(registered, cmap='gray')\n",
    "plt.title('Restored Digit')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digit-restoration-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
